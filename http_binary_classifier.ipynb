{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier on HTTP CSIC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = pd.read_csv(\"normalTrafficTraining_http_requests.csv\")\n",
    "normalTestDataFrame = pd.read_csv(\"normalTrafficTest_http_requests.csv\")\n",
    "anomalousTestDataFrame = pd.read_csv(\"anomalousTrafficTest_http_requests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame = normalTrainingDataFrame.append(normalTestDataFrame, ignore_index=True)\n",
    "combinedDataFrame = combinedDataFrame.append(anomalousTestDataFrame, ignore_index=True)\n",
    "combinedDataFrame = combinedDataFrame.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns where feature is trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = len(combinedDataFrame.columns)\n",
    "cols_to_drop_index = []\n",
    "\n",
    "\n",
    "for i in range(num_columns):\n",
    "    if len(combinedDataFrame.iloc[:,i].value_counts()) == 1:\n",
    "        cols_to_drop_index = cols_to_drop_index + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_columns = combinedDataFrame.columns\n",
    "cols_to_drop_name = []\n",
    "\n",
    "for i in range(len(cols_to_drop_index)):\n",
    "    next_drop = combined_df_columns[cols_to_drop_index[i]]\n",
    "    cols_to_drop_name = cols_to_drop_name + [next_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame.drop(cols_to_drop_name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Manipulation of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['Host'] = combinedDataFrame['Host'].apply(lambda x: x[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JSESSIONID=    97065\n",
       "Name: Cookie, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDataFrame['Cookie'].apply(lambda x: x[:11]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['Cookie'] = combinedDataFrame['Cookie'].apply(lambda x: x[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame.rename(columns={'Cookie':'Cookie_JSESSIONID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://localhost:8080    97065\n",
       "Name: Request_Address, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"http://localhost:8080\")\n",
    "combinedDataFrame['Request_Address'].apply(lambda x: x[:21]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame.rename(columns={'Request_Address':'Request_Address_URI'}, inplace=True)\n",
    "combinedDataFrame['Request_Address_URI'] = combinedDataFrame['Request_Address_URI'].apply(lambda x: x[21:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['Content-Length'] = combinedDataFrame['Content-Length'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal_Access  Request_Type\n",
       "No             GET             15088\n",
       "               POST             9580\n",
       "               PUT               397\n",
       "Yes            GET             56000\n",
       "               POST            16000\n",
       "Name: Request_Type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDataFrame.groupby('Normal_Access')['Request_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal_Access  Host\n",
       "No             8080    24668\n",
       "               9090      397\n",
       "Yes            8080    72000\n",
       "Name: Host, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDataFrame.groupby('Normal_Access')['Host'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping column as every session ID in table is unique, cannot link attacks to particular sessions\n",
    "combinedDataFrame = combinedDataFrame.drop(columns='Cookie_JSESSIONID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ordering columns\n",
    "cols = combinedDataFrame.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "combinedDataFrame = combinedDataFrame[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['No_of_slashes'] = combinedDataFrame.apply(lambda row: row.Request_Address_URI.count(\"/\"), axis=1)\n",
    "combinedDataFrame['No_of_questions'] = combinedDataFrame.apply(lambda row: row.Request_Address_URI.count(\"?\"), axis=1)\n",
    "combinedDataFrame['No_of_equals'] = combinedDataFrame.apply(lambda row: row.Request_Address_URI.count(\"=\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['Put_Request'] = combinedDataFrame['Request_Type'] == \"PUT\"\n",
    "combinedDataFrame['9090_Port'] =  combinedDataFrame['Host'] == \"9090\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Put_Request  9090_Port\n",
       "False        False        96668\n",
       "True         True           397\n",
       "Name: 9090_Port, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDataFrame.groupby('Put_Request')['9090_Port'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame = combinedDataFrame.drop(columns='9090_Port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame.rename(columns={'Put_Request':'PUT_and_9090'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['No_of_ampersands'] = combinedDataFrame.apply(lambda row: row.Request_Address_URI.count(\"&\"), axis=1)\n",
    "combinedDataFrame['No_of_periods'] = combinedDataFrame.apply(lambda row: row.Request_Address_URI.count(\".\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['Length_of_URI'] = combinedDataFrame.apply(lambda row: len(row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(uri):\n",
    "    tokens = uri.split(\".\")\n",
    "    if len(tokens)==1:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return tokens[len(tokens)-1]\n",
    "    \n",
    "def get_final_file(uri):\n",
    "    tokens = uri.split(\"/\")\n",
    "    return tokens[len(tokens)-1]\n",
    "\n",
    "# To try and find bad extensions\n",
    "def max_no_of_periods_between_slashes(uri):\n",
    "    num_found = 0\n",
    "    tokens = uri.split(\"/\")\n",
    "    for token in tokens:\n",
    "        num_in_token = token.count(\".\")\n",
    "        if num_in_token > num_found:\n",
    "            num_found = num_in_token\n",
    "    return num_found    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['URI_ext'] = combinedDataFrame.apply(lambda row: get_ext(row.Request_Address_URI), axis=1)\n",
    "combinedDataFrame['URI_file'] = combinedDataFrame.apply(lambda row: get_final_file(row.Request_Address_URI), axis=1)\n",
    "combinedDataFrame['Max_no_periods_between_slashes'] = combinedDataFrame.apply(lambda row: max_no_of_periods_between_slashes(row.Request_Address_URI), axis=1)\n",
    "combinedDataFrame['URI_ext_end_with_alpha'] = combinedDataFrame.apply(lambda row: row.URI_ext[-1:].isalpha(), axis=1)\n",
    "combinedDataFrame['URI_ext_end_with_numeric'] = combinedDataFrame.apply(lambda row: row.URI_ext[-1:].isdigit(), axis=1)\n",
    "combinedDataFrame['URI_has_CAPS'] = combinedDataFrame.apply(lambda row: any(x.isupper() for x in row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only port 9090 has attacks, rest is port 8080\n",
    "combinedDataFrame = combinedDataFrame.drop(columns='Host')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['URI_ext_shortened'] = combinedDataFrame.apply(lambda row: row.URI_ext[:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entropy, other features\n",
    "\n",
    "import math\n",
    "\n",
    "# Referenced from https://stackoverflow.com/questions/1547899/which-characters-make-a-url-invalid \n",
    "URI_CHARS_LIST = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~:/?#[]@!$&'()*+,;=\"\n",
    "\n",
    "def shannon_entropy(data, iterator):\n",
    "    \"\"\"\n",
    "    Borrowed from http://blog.dkbza.org/2007/05/scanning-data-for-entropy-anomalies.html\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return 0\n",
    "    entropy = 0\n",
    "    for x in iterator:\n",
    "        p_x = float(data.count(x))/len(data)\n",
    "        if p_x > 0:\n",
    "            entropy += - p_x*math.log(p_x, 2)\n",
    "    return entropy\n",
    "\n",
    "combinedDataFrame['Entropy'] = combinedDataFrame.apply(lambda row: shannon_entropy(row.Request_Address_URI, URI_CHARS_LIST), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDataFrame['Length_of_URI_File'] = combinedDataFrame.apply(lambda row: len(row.URI_file), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Attacks Detection\n",
    "\n",
    "# To detect JSESSION_ID in URL Rewrite, none of rows contain \"jsessionid=\"\n",
    "combinedDataFrame['Has_set-cookie'] = combinedDataFrame.apply(lambda row: \"Set-cookie\" in row.Request_Address_URI, axis=1)\n",
    "# Identify accesses to backup files\n",
    "combinedDataFrame['Access_backup'] = combinedDataFrame.apply(lambda row: (row.URI_ext).lower() == \"bak\", axis=1)\n",
    "# Identify accesses to config files\n",
    "combinedDataFrame['Access_config'] = combinedDataFrame.apply(lambda row: (row.URI_ext).lower() == \"cnf\", axis=1)\n",
    "# Identify accesses to default index.html file\n",
    "combinedDataFrame['Access_index_html'] = combinedDataFrame.apply(lambda row: \"index.html\" in row.Request_Address_URI, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Dynamic Attacks Detection\n",
    "\n",
    "# Identify possible SQL Commands\n",
    "# can change to a count rather than binary\n",
    "def spot_sql(uri):\n",
    "    return (\"SELECT\" in uri or \"FROM\" in uri or \"UNION\" in uri or \"OR\" in uri or \"--\" in uri or \"/**/\" in uri or \"INSERT\" in uri or \"UPDATE\" in uri or \"DELETE\" in uri or \"CREATE\" in uri or \"ALTER\" in uri or \"DROP\" in uri)\n",
    "\n",
    "combinedDataFrame['Possible_SQL_Injection'] = combinedDataFrame.apply(lambda row: spot_sql(row.Request_Address_URI), axis=1)\n",
    "\n",
    "# Possible CRLF injection - not found\n",
    "crlf_list = combinedDataFrame.apply(lambda row: \"%0d%0a\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "count_crlf =0\n",
    "for lin in crlf_list:\n",
    "    if lin:\n",
    "        count_crlf = count_crlf + 1\n",
    "        \n",
    "print(count_crlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross site scripting\n",
    "combinedDataFrame['Contains_script_word'] = combinedDataFrame.apply(lambda row: \"script\" in row.Request_Address_URI.lower(), axis=1)\n",
    "combinedDataFrame['Contains_another_http'] = combinedDataFrame.apply(lambda row: \"http\" in row.Request_Address_URI.lower(), axis=1)\n",
    "\n",
    "# Buffer overflows\n",
    "# No feature I can find to detect this threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns, enumeration to form dataFrame\n",
    "testingDataFrame = combinedDataFrame.drop(columns=['Request_Address_URI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal_Access</th>\n",
       "      <th>Request_Type</th>\n",
       "      <th>Content-Length</th>\n",
       "      <th>No_of_slashes</th>\n",
       "      <th>No_of_questions</th>\n",
       "      <th>No_of_equals</th>\n",
       "      <th>PUT_and_9090</th>\n",
       "      <th>No_of_ampersands</th>\n",
       "      <th>No_of_periods</th>\n",
       "      <th>Length_of_URI</th>\n",
       "      <th>...</th>\n",
       "      <th>URI_ext_shortened</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Length_of_URI_File</th>\n",
       "      <th>Has_set-cookie</th>\n",
       "      <th>Access_backup</th>\n",
       "      <th>Access_config</th>\n",
       "      <th>Access_index_html</th>\n",
       "      <th>Possible_SQL_Injection</th>\n",
       "      <th>Contains_script_word</th>\n",
       "      <th>Contains_another_http</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>GET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>jsp</td>\n",
       "      <td>3.614369</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>GET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>jsp</td>\n",
       "      <td>4.544789</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>POST</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>jsp</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>GET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>jsp</td>\n",
       "      <td>4.584236</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>POST</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>jsp</td>\n",
       "      <td>4.018082</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Normal_Access Request_Type  Content-Length  No_of_slashes  No_of_questions  \\\n",
       "0           Yes          GET             0.0              2                0   \n",
       "1           Yes          GET             0.0              3                1   \n",
       "2           Yes         POST            68.0              3                0   \n",
       "3           Yes          GET             0.0              3                1   \n",
       "4           Yes         POST            63.0              3                0   \n",
       "\n",
       "   No_of_equals  PUT_and_9090  No_of_ampersands  No_of_periods  Length_of_URI  \\\n",
       "0             0         False                 0              1             18   \n",
       "1             5         False                 4              1             96   \n",
       "2             0         False                 0              1             27   \n",
       "3             5         False                 4              1             95   \n",
       "4             0         False                 0              1             31   \n",
       "\n",
       "           ...           URI_ext_shortened   Entropy  Length_of_URI_File  \\\n",
       "0          ...                         jsp  3.614369                   9   \n",
       "1          ...                         jsp  4.544789                  79   \n",
       "2          ...                         jsp  4.004344                  10   \n",
       "3          ...                         jsp  4.584236                  78   \n",
       "4          ...                         jsp  4.018082                  14   \n",
       "\n",
       "   Has_set-cookie  Access_backup  Access_config Access_index_html  \\\n",
       "0           False          False          False             False   \n",
       "1           False          False          False             False   \n",
       "2           False          False          False             False   \n",
       "3           False          False          False             False   \n",
       "4           False          False          False             False   \n",
       "\n",
       "   Possible_SQL_Injection  Contains_script_word  Contains_another_http  \n",
       "0                   False                 False                  False  \n",
       "1                   False                 False                  False  \n",
       "2                   False                 False                  False  \n",
       "3                   False                 False                  False  \n",
       "4                   False                 False                  False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingDataFrame = testingDataFrame.replace([True, False], [1, 0])\n",
    "testingDataFrame = testingDataFrame.replace(['No', 'Yes'], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENUMERATING REQUEST TYPE\n",
    "testingDataFrame = testingDataFrame.replace([\"GET\", \"POST\", \"PUT\"], [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping these columns: URI ext, URI file, URI_ext_shortened (value already extracted in pre-processing?)\n",
    "testingDataFrame = testingDataFrame.drop(columns=['URI_ext', 'URI_file', 'URI_ext_shortened'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Baseline Models Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sampling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "combined_table_features = testingDataFrame.drop(columns='Normal_Access')\n",
    "combined_table_target = testingDataFrame['Normal_Access']\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(combined_table_features, combined_table_target, test_size=0.1, shuffle=True, stratify=combined_table_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf_lin = SVC(kernel='linear')\n",
    "svc_clf_lin.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_rbf = SVC()\n",
    "svc_clf_rbf.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "result_df_columns = ['Classifier', 'Accuracy', 'Precision (Micro)', 'Precision (Weighted)', 'Recall (Micro)', 'Recall (Weighted)', 'F-1 (Micro)', 'F1 (Weighted)']\n",
    "clf_cmp_dataframe = pd.DataFrame(columns=result_df_columns)\n",
    "\n",
    "rf_pred_list = rf_clf.predict(test_features)\n",
    "rf_acc = accuracy_score(test_target, rf_pred_list)\n",
    "rf_prec_mic = precision_score(test_target, rf_pred_list, average='micro')\n",
    "rf_prec_mac = precision_score(test_target, rf_pred_list, average='weighted')\n",
    "rf_rec_mic = recall_score(test_target, rf_pred_list, average='micro')\n",
    "rf_rec_mac = recall_score(test_target, rf_pred_list, average='weighted')\n",
    "rf_f1_mic = f1_score(test_target, rf_pred_list, average='micro')\n",
    "rf_f1_mac = f1_score(test_target, rf_pred_list, average='weighted')\n",
    "\n",
    "rf_res = [\"RF\", rf_acc, rf_prec_mic, rf_prec_mac, rf_rec_mic, rf_rec_mac, rf_f1_mic, rf_f1_mac]\n",
    "rf_df = pd.DataFrame([rf_res], columns=result_df_columns)\n",
    "\n",
    "clf_cmp_dataframe = clf_cmp_dataframe.append(rf_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "\n",
    "lr_pred_list = lr_clf.predict(test_features)\n",
    "lr_acc = accuracy_score(test_target, lr_pred_list)\n",
    "lr_prec_mic = precision_score(test_target, lr_pred_list, average='micro')\n",
    "lr_prec_mac = precision_score(test_target, lr_pred_list, average='weighted')\n",
    "lr_rec_mic = recall_score(test_target, lr_pred_list, average='micro')\n",
    "lr_rec_mac = recall_score(test_target, lr_pred_list, average='weighted')\n",
    "lr_f1_mic = f1_score(test_target, lr_pred_list, average='micro')\n",
    "lr_f1_mac = f1_score(test_target, lr_pred_list, average='weighted')\n",
    "\n",
    "lr_res = [\"LR\", lr_acc, lr_prec_mic, lr_prec_mac, lr_rec_mic, lr_rec_mac, lr_f1_mic, lr_f1_mac]\n",
    "lr_df = pd.DataFrame([lr_res], columns=result_df_columns)\n",
    "\n",
    "clf_cmp_dataframe = clf_cmp_dataframe.append(lr_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC linear\n",
    "svc_lin_pred_list = svc_clf_lin.predict(test_features)\n",
    "svc_lin_acc = accuracy_score(test_target, svc_lin_pred_list)\n",
    "svc_lin_prec_mic = precision_score(test_target, svc_lin_pred_list, average='micro')\n",
    "svc_lin_prec_mac = precision_score(test_target, svc_lin_pred_list, average='weighted')\n",
    "svc_lin_rec_mic = recall_score(test_target, svc_lin_pred_list, average='micro')\n",
    "svc_lin_rec_mac = recall_score(test_target, svc_lin_pred_list, average='weighted')\n",
    "svc_lin_f1_mic = f1_score(test_target, svc_lin_pred_list, average='micro')\n",
    "svc_lin_f1_mac = f1_score(test_target, svc_lin_pred_list, average='weighted')\n",
    "\n",
    "svc_lin_res = [\"SVC Linear\", svc_lin_acc, svc_lin_prec_mic, svc_lin_prec_mac, svc_lin_rec_mic, svc_lin_rec_mac, svc_lin_f1_mic, svc_lin_f1_mac]\n",
    "svc_lin_df = pd.DataFrame([svc_lin_res], columns=result_df_columns)\n",
    "\n",
    "clf_cmp_dataframe = clf_cmp_dataframe.append(svc_lin_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC rbf\n",
    "svc_rbf_pred_list = svc_clf_rbf.predict(test_features)\n",
    "svc_rbf_acc = accuracy_score(test_target, svc_rbf_pred_list)\n",
    "svc_rbf_prec_mic = precision_score(test_target, svc_rbf_pred_list, average='micro')\n",
    "svc_rbf_prec_mac = precision_score(test_target, svc_rbf_pred_list, average='weighted')\n",
    "svc_rbf_rec_mic = recall_score(test_target, svc_rbf_pred_list, average='micro')\n",
    "svc_rbf_rec_mac = recall_score(test_target, svc_rbf_pred_list, average='weighted')\n",
    "svc_rbf_f1_mic = f1_score(test_target, svc_rbf_pred_list, average='micro')\n",
    "svc_rbf_f1_mac = f1_score(test_target, svc_rbf_pred_list, average='weighted')\n",
    "\n",
    "svc_rbf_res = [\"SVC RBF\", svc_rbf_acc, svc_rbf_prec_mic, svc_rbf_prec_mac, svc_rbf_rec_mic, svc_rbf_rec_mac, svc_rbf_f1_mic, svc_rbf_f1_mac]\n",
    "svc_rbf_df = pd.DataFrame([svc_rbf_res], columns=result_df_columns)\n",
    "\n",
    "clf_cmp_dataframe = clf_cmp_dataframe.append(svc_rbf_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Micro)</th>\n",
       "      <th>Precision (Weighted)</th>\n",
       "      <th>Recall (Micro)</th>\n",
       "      <th>Recall (Weighted)</th>\n",
       "      <th>F-1 (Micro)</th>\n",
       "      <th>F1 (Weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>0.918938</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>0.918064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.820112</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.794078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC Linear</td>\n",
       "      <td>0.816112</td>\n",
       "      <td>0.816112</td>\n",
       "      <td>0.816651</td>\n",
       "      <td>0.816112</td>\n",
       "      <td>0.816112</td>\n",
       "      <td>0.816112</td>\n",
       "      <td>0.789326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC RBF</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>0.921309</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>0.909986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier  Accuracy  Precision (Micro)  Precision (Weighted)  \\\n",
       "0          RF  0.919955           0.919955              0.918938   \n",
       "1          LR  0.819409           0.819409              0.820112   \n",
       "2  SVC Linear  0.816112           0.816112              0.816651   \n",
       "3     SVC RBF  0.915319           0.915319              0.921309   \n",
       "\n",
       "   Recall (Micro)  Recall (Weighted)  F-1 (Micro)  F1 (Weighted)  \n",
       "0        0.919955           0.919955     0.919955       0.918064  \n",
       "1        0.819409           0.819409     0.819409       0.794078  \n",
       "2        0.816112           0.816112     0.816112       0.789326  \n",
       "3        0.915319           0.915319     0.915319       0.909986  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cmp_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Baseline Models\n",
    "As seen from the table above, 2 models clearly perform better than the other 2. The Random Forest Classifier and SVC with RBF kernel are the better performing classifiers, with similar results. In this scenario, we would choose an evaluation metrics skewed towards recall over precision, as we would want as few false negatives, in order to detect as many attacks that happened. This would be a safer stance, as any possible attack should be investigated to mitigate the damage. As such, I would prefer choosing RF over SVC with RBF kernel. The RBF kernel SVC also is expensive to implement, as it takes lots of time to run, for marginal gains weighted precision, while doing worse than RF in each other evaluation metric. Hence, I would choose the RF as the baseline model for future iterations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Future Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Entropy</td>\n",
       "      <td>0.235893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content-Length</td>\n",
       "      <td>0.209897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Length_of_URI_File</td>\n",
       "      <td>0.128779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Length_of_URI</td>\n",
       "      <td>0.105749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Request_Type</td>\n",
       "      <td>0.077284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Importance\n",
       "13             Entropy    0.235893\n",
       "1       Content-Length    0.209897\n",
       "14  Length_of_URI_File    0.128779\n",
       "8        Length_of_URI    0.105749\n",
       "0         Request_Type    0.077284"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "feature_impt_df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
    "\n",
    "for i in range(len(train_features.columns)):\n",
    "    this_feature = pd.DataFrame([[train_features.columns[i], rf_clf.feature_importances_[i]]], columns=['Feature', 'Importance'])\n",
    "    feature_impt_df = feature_impt_df.append(this_feature, ignore_index=True)\n",
    "    \n",
    "feature_impt_df.sort_values('Importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the table above, some features are more important than the others. I can then selectively choose these important features, to prune the selection of features, in order to try and improve the performance of the random forest. In order to justify this selection of \"important features\", I will try to seek a second opinion by running Recursive Feature Elimination to select another set of \"important features\", and look for the overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rf_clf_rfe = RandomForestClassifier()\n",
    "selector = RFE(rf_clf_rfe, 5)\n",
    "selector = selector.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content-Length</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Length_of_URI_File</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Entropy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No_of_periods</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Length_of_URI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature Rank\n",
       "1       Content-Length    1\n",
       "14  Length_of_URI_File    1\n",
       "13             Entropy    1\n",
       "7        No_of_periods    1\n",
       "8        Length_of_URI    1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_feat_rank_df = pd.DataFrame(columns=['Feature', 'Rank'])\n",
    "\n",
    "for i in range(len(train_features.columns)):\n",
    "    this_feature = pd.DataFrame([[train_features.columns[i], selector.ranking_[i]]], columns=['Feature', 'Rank'])\n",
    "    rfe_feat_rank_df = rfe_feat_rank_df.append(this_feature, ignore_index=True)\n",
    "    \n",
    "rfe_feat_rank_df.sort_values('Rank').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the table above, the features chosen by the RFE are very similar to those chosen by the Random Forest's feature importance attribute. As 4 of the 5 features selected overlap in terms of ranking, I would only consider these 4 features as the \"most important features\" - Entropy, Content-Length, Length_of_URI_File, and Length_of_URI. The last 2 features may have a little overlap in terms of content, but I feel that it is different enough to be considered 2 different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model re-made with only 4 Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_impt_features = combined_table_features[['Content-Length', 'Length_of_URI_File', 'Entropy', 'Length_of_URI']]\n",
    "\n",
    "retrain_features, retest_features, retrain_target, retest_target = train_test_split(most_impt_features, combined_table_target, test_size=0.1, shuffle=True, stratify=combined_table_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_retrain = RandomForestClassifier()\n",
    "rf_clf_retrain.fit(retrain_features, retrain_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Recall: 0.9178943030802513\n",
      "Weighted Recall: 0.9178943030802513\n"
     ]
    }
   ],
   "source": [
    "rf_clf_retrain_preds = rf_clf_retrain.predict(retest_features)\n",
    "\n",
    "rf_re_rec_mic = recall_score(retest_target, rf_clf_retrain_preds, average='micro')\n",
    "rf_re_rec_mac = recall_score(retest_target, rf_clf_retrain_preds, average='weighted')\n",
    "\n",
    "print(\"Micro Recall: \" + str(rf_re_rec_mic))\n",
    "print(\"Weighted Recall: \" + str(rf_re_rec_mac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the recall scores above, this new model actually performs worse than the original model by a small margin. The fact that choosing these features via RFE ended up making a sub-optimal model can be attributed to the way RF are implemented, where each feature is considered at each split in a decision tree. By dropping certain features, which aren't as important as the 4 I selected, but are still significant enough to help improve the model rather than noise that disrupts the model. More optimistically, having almost as good a recall score (0.2 off) with only 4 features shows how important these 4 features are. In an environment where costs are of high importance, we could possibly trade-off this diminished performance for a lesser cost, in essence a lower recall score of 0.2 for considering 18 less features, to create a smaller pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators':[10,50,100,200], 'max_depth':[None,3,4,5,8,10,12,15,18,20,22]}\n",
    "\n",
    "rf_clf_gridsearch = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'max_depth': 20}\n",
      "0.9244144783534421\n"
     ]
    }
   ],
   "source": [
    "gscv_clf = GridSearchCV(rf_clf_gridsearch, parameters)\n",
    "gscv_clf.fit(train_features, train_target)\n",
    "\n",
    "print(gscv_clf.best_params_)\n",
    "print(gscv_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold CV on Ideal RF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the claims by the Grid Search CV that the ideal model has 200 estimators and a max depth of 20, I would perform K-Folds CV to check the performance of this RF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251325967051379"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "rf_clf_k = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "\n",
    "np.mean(cross_val_score(rf_clf_k, combined_table_features, combined_table_target, cv=kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With K-Folds CV, the model given by Grid Search CV once again performs better than the default RF used in earlier sections, and justifies the claims that this model is indeed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 - Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
