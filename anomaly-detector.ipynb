{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detector on HTTP CSIC Dataset\n",
    "\n",
    "The goal of this report is to learn how to use a different approach from binary classifiers, specifically how anomaly detectors are trained. Unlike binary classifiers where classes are usually equally represented in the population, anomaly detectors are more useful in populations where normal data exists a lot more than anomalous data points. Hence, the training set used in this report will purely be normal data, unlike stratified splits in other binary classifiers' exploration. While similar models are used, OneClassSVM and IsolationForests are slightly different from SVM and RandomForestClassifiers. At the end of the report, I hope to have been able to choose a specific model as my best choice in being utilised as an anomaly detector for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = pd.read_csv(\"normalTrafficTraining_http_requests.csv\")\n",
    "normalTestDataFrame = pd.read_csv(\"normalTrafficTest_http_requests.csv\")\n",
    "anomalousTestDataFrame = pd.read_csv(\"anomalousTrafficTest_http_requests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataFrame = normalTestDataFrame.append(anomalousTestDataFrame, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.drop(columns=\"Unnamed: 0\")\n",
    "testDataFrame = testDataFrame.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Trivial Features' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the indexes of the columns to drop\n",
    "\n",
    "num_columns = len(testDataFrame.columns)\n",
    "cols_to_drop_index = []\n",
    "\n",
    "for i in range(num_columns):\n",
    "    if len(testDataFrame.iloc[:,i].value_counts()) == 1:\n",
    "        cols_to_drop_index = cols_to_drop_index + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the name of the columns to drop\n",
    "\n",
    "df_columns = testDataFrame.columns\n",
    "cols_to_drop_name = []\n",
    "\n",
    "for i in range(len(cols_to_drop_index)):\n",
    "    next_drop = df_columns[cols_to_drop_index[i]]\n",
    "    cols_to_drop_name = cols_to_drop_name + [next_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame.drop(cols_to_drop_name, axis=1, inplace=True)\n",
    "testDataFrame.drop(cols_to_drop_name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ordering columns\n",
    "def re_order_last_col_to_front(df):\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = re_order_last_col_to_front(normalTrainingDataFrame)\n",
    "testDataFrame = re_order_last_col_to_front(testDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Manipulation - Based on experience in the binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.drop(columns=['Host', 'Cookie'])\n",
    "testDataFrame = testDataFrame.drop(columns=['Host', 'Cookie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping \"http://localhost:8080\" from request_addres\n",
    "normalTrainingDataFrame.rename(columns={'Request_Address':'Request_Address_URI'}, inplace=True)\n",
    "testDataFrame.rename(columns={'Request_Address':'Request_Address_URI'}, inplace=True)\n",
    "normalTrainingDataFrame['Request_Address_URI'] = normalTrainingDataFrame['Request_Address_URI'].apply(lambda x: x[21:])\n",
    "testDataFrame['Request_Address_URI'] = testDataFrame['Request_Address_URI'].apply(lambda x: x[21:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Content-Length'] = normalTrainingDataFrame['Content-Length'].replace(np.nan, 0)\n",
    "testDataFrame['Content-Length'] = testDataFrame['Content-Length'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['No_of_slashes'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"/\"), axis=1)\n",
    "normalTrainingDataFrame['No_of_questions'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"?\"), axis=1)\n",
    "normalTrainingDataFrame['No_of_equals'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"=\"), axis=1)\n",
    "\n",
    "testDataFrame['No_of_slashes'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"/\"), axis=1)\n",
    "testDataFrame['No_of_questions'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"?\"), axis=1)\n",
    "testDataFrame['No_of_equals'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"=\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Put_Request'] = normalTrainingDataFrame['Request_Type'] == \"PUT\"\n",
    "testDataFrame['Put_Request'] = testDataFrame['Request_Type'] == \"PUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['No_of_ampersands'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"&\"), axis=1)\n",
    "normalTrainingDataFrame['No_of_periods'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\".\"), axis=1)\n",
    "\n",
    "testDataFrame['No_of_ampersands'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"&\"), axis=1)\n",
    "testDataFrame['No_of_periods'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\".\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Length_of_URI'] = normalTrainingDataFrame.apply(lambda row: len(row.Request_Address_URI), axis=1)\n",
    "\n",
    "testDataFrame['Length_of_URI'] = testDataFrame.apply(lambda row: len(row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(uri):\n",
    "    tokens = uri.split(\".\")\n",
    "    if len(tokens)==1:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return tokens[len(tokens)-1]\n",
    "    \n",
    "def get_final_file(uri):\n",
    "    tokens = uri.split(\"/\")\n",
    "    return tokens[len(tokens)-1]\n",
    "\n",
    "# To try and find bad extensions\n",
    "def max_no_of_periods_between_slashes(uri):\n",
    "    num_found = 0\n",
    "    tokens = uri.split(\"/\")\n",
    "    for token in tokens:\n",
    "        num_in_token = token.count(\".\")\n",
    "        if num_in_token > num_found:\n",
    "            num_found = num_in_token\n",
    "    return num_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['URI_ext'] = normalTrainingDataFrame.apply(lambda row: get_ext(row.Request_Address_URI), axis=1)\n",
    "normalTrainingDataFrame['URI_file'] = normalTrainingDataFrame.apply(lambda row: get_final_file(row.Request_Address_URI), axis=1)\n",
    "normalTrainingDataFrame['Max_no_periods_between_slashes'] = normalTrainingDataFrame.apply(lambda row: max_no_of_periods_between_slashes(row.Request_Address_URI), axis=1)\n",
    "normalTrainingDataFrame['URI_ext_end_with_alpha'] = normalTrainingDataFrame.apply(lambda row: row.URI_ext[-1:].isalpha(), axis=1)\n",
    "normalTrainingDataFrame['URI_ext_end_with_numeric'] = normalTrainingDataFrame.apply(lambda row: row.URI_ext[-1:].isdigit(), axis=1)\n",
    "normalTrainingDataFrame['URI_has_CAPS'] = normalTrainingDataFrame.apply(lambda row: any(x.isupper() for x in row.Request_Address_URI), axis=1)\n",
    "\n",
    "testDataFrame['URI_ext'] = testDataFrame.apply(lambda row: get_ext(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['URI_file'] = testDataFrame.apply(lambda row: get_final_file(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['Max_no_periods_between_slashes'] = testDataFrame.apply(lambda row: max_no_of_periods_between_slashes(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['URI_ext_end_with_alpha'] = testDataFrame.apply(lambda row: row.URI_ext[-1:].isalpha(), axis=1)\n",
    "testDataFrame['URI_ext_end_with_numeric'] = testDataFrame.apply(lambda row: row.URI_ext[-1:].isdigit(), axis=1)\n",
    "testDataFrame['URI_has_CAPS'] = testDataFrame.apply(lambda row: any(x.isupper() for x in row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['URI_ext_shortened'] = normalTrainingDataFrame.apply(lambda row: row.URI_ext[:3], axis=1)\n",
    "\n",
    "testDataFrame['URI_ext_shortened'] = testDataFrame.apply(lambda row: row.URI_ext[:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Referenced from https://stackoverflow.com/questions/1547899/which-characters-make-a-url-invalid \n",
    "URI_CHARS_LIST = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~:/?#[]@!$&'()*+,;=\"\n",
    "\n",
    "def shannon_entropy(data, iterator):\n",
    "    \"\"\"\n",
    "    Borrowed from http://blog.dkbza.org/2007/05/scanning-data-for-entropy-anomalies.html\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return 0\n",
    "    entropy = 0\n",
    "    for x in iterator:\n",
    "        p_x = float(data.count(x))/len(data)\n",
    "        if p_x > 0:\n",
    "            entropy += - p_x*math.log(p_x, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Entropy'] = normalTrainingDataFrame.apply(lambda row: shannon_entropy(row.Request_Address_URI, URI_CHARS_LIST), axis=1)\n",
    "\n",
    "testDataFrame['Entropy'] = testDataFrame.apply(lambda row: shannon_entropy(row.Request_Address_URI, URI_CHARS_LIST), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Length_of_URI_File'] = normalTrainingDataFrame.apply(lambda row: len(row.URI_file), axis=1)\n",
    "\n",
    "testDataFrame['Length_of_URI_File'] = testDataFrame.apply(lambda row: len(row.URI_file), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Attacks Detection\n",
    "\n",
    "# To detect JSESSION_ID in URL Rewrite, none of rows contain \"jsessionid=\"\n",
    "normalTrainingDataFrame['Has_set-cookie'] = normalTrainingDataFrame.apply(lambda row: \"Set-cookie\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "testDataFrame['Has_set-cookie'] = testDataFrame.apply(lambda row: \"Set-cookie\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "# Identify accesses to backup files\n",
    "normalTrainingDataFrame['Access_backup'] = normalTrainingDataFrame.apply(lambda row: (row.URI_ext).lower() == \"bak\", axis=1)\n",
    "\n",
    "testDataFrame['Access_backup'] = testDataFrame.apply(lambda row: (row.URI_ext).lower() == \"bak\", axis=1)\n",
    "\n",
    "# Identify accesses to config files\n",
    "normalTrainingDataFrame['Access_config'] = normalTrainingDataFrame.apply(lambda row: (row.URI_ext).lower() == \"cnf\", axis=1)\n",
    "\n",
    "testDataFrame['Access_config'] = testDataFrame.apply(lambda row: (row.URI_ext).lower() == \"cnf\", axis=1)\n",
    "\n",
    "# Identify accesses to default index.html file\n",
    "normalTrainingDataFrame['Access_index_html'] = normalTrainingDataFrame.apply(lambda row: \"index.html\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "testDataFrame['Access_index_html'] = testDataFrame.apply(lambda row: \"index.html\" in row.Request_Address_URI, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Attacks Detection\n",
    "\n",
    "# Identify possible SQL Commands\n",
    "def spot_sql(uri):\n",
    "    return (\"SELECT\" in uri or \"FROM\" in uri or \"UNION\" in uri or \"OR\" in uri or \"--\" in uri or \"/**/\" in uri or \"INSERT\" in uri or \"UPDATE\" in uri or \"DELETE\" in uri or \"CREATE\" in uri or \"ALTER\" in uri or \"DROP\" in uri)\n",
    "\n",
    "normalTrainingDataFrame['Possible_SQL_Injection'] = normalTrainingDataFrame.apply(lambda row: spot_sql(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['Possible_SQL_Injection'] = testDataFrame.apply(lambda row: spot_sql(row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross site scripting\n",
    "normalTrainingDataFrame['Contains_script_word'] = normalTrainingDataFrame.apply(lambda row: \"script\" in row.Request_Address_URI.lower(), axis=1)\n",
    "normalTrainingDataFrame['Contains_script_word'] = normalTrainingDataFrame.apply(lambda row: \"script\" in row.Request_Address_URI.lower(), axis=1)\n",
    "\n",
    "testDataFrame['Contains_another_http'] = testDataFrame.apply(lambda row: \"http\" in row.Request_Address_URI.lower(), axis=1)\n",
    "testDataFrame['Contains_another_http'] = testDataFrame.apply(lambda row: \"http\" in row.Request_Address_URI.lower(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidying up of Table - Enumeration and Dropping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.drop(columns=['URI_ext', 'URI_file', 'URI_ext_shortened', 'Request_Address_URI', 'Request_Type'])\n",
    "testDataFrame = testDataFrame.drop(columns=['URI_ext', 'URI_file', 'URI_ext_shortened', 'Request_Address_URI', 'Request_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.replace([True, False], [1, 0])\n",
    "normalTrainingDataFrame = normalTrainingDataFrame.replace(['No', 'Yes'], [-1,1])\n",
    "\n",
    "testDataFrame = testDataFrame.replace([True, False], [1, 0])\n",
    "testDataFrame = testDataFrame.replace(['No', 'Yes'], [-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalTrainingDataFrame.drop(columns='Normal_Access')\n",
    "y_train = normalTrainingDataFrame['Normal_Access']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testDataFrame.drop(columns='Normal_Access')\n",
    "y_test = testDataFrame['Normal_Access']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One class svm\n",
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.OneClassSVM()\n",
    "svm_clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "result_df_columns = ['Classifier', 'Accuracy', 'Precision (Binary)', 'Recall (Binary)', 'F1 (Binary)']\n",
    "results_dataframe = pd.DataFrame(columns=result_df_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_acc = accuracy_score(y_test, y_pred_test)\n",
    "x_test_prec = precision_score(y_test, y_pred_test, average='binary')\n",
    "x_test_rec = recall_score(y_test, y_pred_test, average='binary')\n",
    "x_test_f1 = f1_score(y_test, y_pred_test, average='binary')\n",
    "\n",
    "x_test_res = [\"One Class SVM\", x_test_acc, x_test_prec, x_test_rec, x_test_f1]\n",
    "x_test_df = pd.DataFrame([x_test_res], columns=result_df_columns)\n",
    "\n",
    "results_dataframe = results_dataframe.append(x_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(bootstrap=False, contamination=0.1, max_features=1.0,\n",
       "        max_samples='auto', n_estimators=100, n_jobs=1, random_state=None,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolation forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "forest_clf = IsolationForest()\n",
    "forest_clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forest_pred_test = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_forest_test_acc = accuracy_score(y_test, y_forest_pred_test)\n",
    "x_forest_test_prec = precision_score(y_test, y_forest_pred_test, average='binary')\n",
    "x_forest_test_rec = recall_score(y_test, y_forest_pred_test, average='binary')\n",
    "x_forest_test_f1 = f1_score(y_test, y_forest_pred_test, average='binary')\n",
    "\n",
    "x_forest_test_res = [\"Isolation Forest\", x_forest_test_acc, x_forest_test_prec, x_forest_test_rec, x_forest_test_f1]\n",
    "x_forest_test_df = pd.DataFrame([x_forest_test_res], columns=result_df_columns)\n",
    "\n",
    "results_dataframe = results_dataframe.append(x_forest_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Binary)</th>\n",
       "      <th>Recall (Binary)</th>\n",
       "      <th>F1 (Binary)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Class SVM</td>\n",
       "      <td>0.662786</td>\n",
       "      <td>0.934322</td>\n",
       "      <td>0.460361</td>\n",
       "      <td>0.616807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0.649226</td>\n",
       "      <td>0.645196</td>\n",
       "      <td>0.899833</td>\n",
       "      <td>0.751531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classifier  Accuracy  Precision (Binary)  Recall (Binary)  \\\n",
       "0     One Class SVM  0.662786            0.934322         0.460361   \n",
       "1  Isolation Forest  0.649226            0.645196         0.899833   \n",
       "\n",
       "   F1 (Binary)  \n",
       "0     0.616807  \n",
       "1     0.751531  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the results show, there is a trade-off to be had, as One Class SVM has high precision but low recall, while Isolation Forest has decent precision and high recall. In order to test this balance, we can consider the F1-Score, which represents the harmonic average between precision and recall. Hence, I would be leaning towards Isolation Forest as a better option. Despite this, I will still consider both One Class SVM and Isolation Forests in future iterations to improve on the current scores achieved. I would also plot a Precision Recall Curve below to analyse the trade-offs further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_y_score = forest_clf.decision_function(X_test)\n",
    "svm_y_score = svm_clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest average precision-recall score: 0.82\n",
      "SVM average precision-recall score: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "forest_average_precision = average_precision_score(y_test, forest_y_score)\n",
    "svm_average_precision = average_precision_score(y_test, svm_y_score)\n",
    "\n",
    "print('Forest average precision-recall score: {0:0.2f}'.format(\n",
    "      forest_average_precision))\n",
    "print('SVM average precision-recall score: {0:0.2f}'.format(\n",
    "      svm_average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Precision Recall Curve for IsolationForest and OneClassSVM')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for_precision, for_recall, for_k = precision_recall_curve(y_test, forest_y_score)\n",
    "svm_precision, svm_recall, svm_k = precision_recall_curve(y_test, svm_y_score)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.step(for_recall, for_precision, color='b', label='Isolation Forest', alpha=0.2,\n",
    "         where='post')\n",
    "plt.step(svm_recall, svm_precision, color='r', label= 'One Class SVM', alpha=0.2,\n",
    "         where='post')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.fill_between(for_recall, for_precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.fill_between(svm_recall, svm_precision, step='post', alpha=0.2,\n",
    "                 color='r')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision Recall Curve for IsolationForest and OneClassSVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the curve plotted, it can be visualised that neither model truly dominates the other model. Hence, I would be referring back to the F1-Score to state a preference towards Isolation Forest, but once again, it has to be explored further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the research done within the binary classifier report, I managed to identify 4 features which seem more important than the others. By only choosing these 4 features to simplify the model, I hope to reduce the curse of dimensionality and test Occam's Razor.\n",
    "\n",
    "### Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced Features\n",
    "most_impt_features_train = X_train[['Content-Length', 'Length_of_URI_File', 'Entropy', 'Length_of_URI']]\n",
    "most_impt_features_test = X_test[['Content-Length', 'Length_of_URI_File', 'Entropy', 'Length_of_URI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content-Length</th>\n",
       "      <th>Length_of_URI_File</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Length_of_URI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.614369</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>4.546791</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>4.435028</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.018082</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Content-Length  Length_of_URI_File   Entropy  Length_of_URI\n",
       "0             0.0                   9  3.614369             18\n",
       "1             0.0                  85  4.546791            102\n",
       "2            74.0                  10  4.004344             27\n",
       "3             0.0                  75  4.435028             92\n",
       "4            60.0                  14  4.018082             31"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_impt_features_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(bootstrap=False, contamination=0.1, max_features=1.0,\n",
       "        max_samples='auto', n_estimators=100, n_jobs=1, random_state=None,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reduced_clf = svm.OneClassSVM()\n",
    "svm_reduced_clf.fit(most_impt_features_train)\n",
    "\n",
    "forest_red_clf = IsolationForest()\n",
    "forest_red_clf.fit(most_impt_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_red_svm_pred_test = svm_reduced_clf.predict(most_impt_features_test)\n",
    "y_red_for_pred_test = forest_red_clf.predict(most_impt_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reducedfeat_dataframe = pd.DataFrame(columns=result_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_red_acc = accuracy_score(y_test, y_red_svm_pred_test)\n",
    "x_test_red_prec = precision_score(y_test, y_red_svm_pred_test, average='binary')\n",
    "x_test_red_rec = recall_score(y_test, y_red_svm_pred_test, average='binary')\n",
    "x_test_red_f1 = f1_score(y_test, y_red_svm_pred_test, average='binary')\n",
    "\n",
    "x_test_red_res = [\"One Class SVM\", x_test_red_acc, x_test_red_prec, x_test_red_rec, x_test_red_f1]\n",
    "x_test_red_df = pd.DataFrame([x_test_red_res], columns=result_df_columns)\n",
    "\n",
    "results_reducedfeat_dataframe = results_reducedfeat_dataframe.append(x_test_red_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reduced_forest_test_acc = accuracy_score(y_test, y_red_for_pred_test)\n",
    "x_reduced_forest_test_prec = precision_score(y_test, y_red_for_pred_test, average='binary')\n",
    "x_reduced_forest_test_rec = recall_score(y_test, y_red_for_pred_test, average='binary')\n",
    "x_reduced_forest_test_f1 = f1_score(y_test, y_red_for_pred_test, average='binary')\n",
    "\n",
    "x_reduced_forest_test_res = [\"Isolation Forest\", x_reduced_forest_test_acc, x_reduced_forest_test_prec, x_reduced_forest_test_rec, x_reduced_forest_test_f1]\n",
    "x_reduced_forest_test_df = pd.DataFrame([x_reduced_forest_test_res], columns=result_df_columns)\n",
    "\n",
    "results_reducedfeat_dataframe = results_reducedfeat_dataframe.append(x_reduced_forest_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Binary)</th>\n",
       "      <th>Recall (Binary)</th>\n",
       "      <th>F1 (Binary)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Class SVM</td>\n",
       "      <td>0.637370</td>\n",
       "      <td>0.989819</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.558392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0.658724</td>\n",
       "      <td>0.653150</td>\n",
       "      <td>0.897972</td>\n",
       "      <td>0.756240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classifier  Accuracy  Precision (Binary)  Recall (Binary)  \\\n",
       "0     One Class SVM  0.637370            0.989819         0.388889   \n",
       "1  Isolation Forest  0.658724            0.653150         0.897972   \n",
       "\n",
       "   F1 (Binary)  \n",
       "0     0.558392  \n",
       "1     0.756240  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_reducedfeat_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the very high precision from the One Class SVM, the trade-off of having such a low recall is not worthwhile. The F1-Score once again leans towards the Isolation Forest as a better option, and I will solely consider the Isolation Forest from here onwards. In order to optimise the model, we can tweak the hyper-parameters to find an ideal set, using Grid Search CV.\n",
    "\n",
    "### Grid Search CV\n",
    "\n",
    "As Isolation Forest does not have a \"score\" method, I have decided to embark on a manual grid search CV exploration. The alternative would have been to develop a callable scoring strategy, which I chose not to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_params = [50,100,150,200,250]\n",
    "max_feats_params = [5,10,15,20,1.0]\n",
    "\n",
    "gscv_df_columns = ['Classifier', 'Estimators', 'Max_feats', 'Accuracy', 'Precision (Binary)', 'Recall (Binary)', 'F1 (Binary)']\n",
    "gscv_dataframe = pd.DataFrame(columns = gscv_df_columns)\n",
    "\n",
    "for i in range(len(estimator_params)):\n",
    "    for j in range(len(max_feats_params)):\n",
    "        if_clf_gscv = IsolationForest(n_estimators=estimator_params[i], max_features=max_feats_params[j])\n",
    "        if_clf_gscv.fit(X_train)\n",
    "        y_gscv_pred_test = if_clf_gscv.predict(X_test)\n",
    "        \n",
    "        x_gscv_test_acc = accuracy_score(y_test, y_gscv_pred_test)\n",
    "        x_gscv_test_prec = precision_score(y_test, y_gscv_pred_test, average='binary')\n",
    "        x_gscv_test_rec = recall_score(y_test, y_gscv_pred_test, average='binary')\n",
    "        x_gscv_test_f1 = f1_score(y_test, y_gscv_pred_test, average='binary')\n",
    "\n",
    "        x_gscv_test_res = [\"Isolation Forest\", estimator_params[i], max_feats_params[j], x_gscv_test_acc, x_gscv_test_prec, x_gscv_test_rec, x_gscv_test_f1]\n",
    "        x_gscv_test_df = pd.DataFrame([x_gscv_test_res], columns=gscv_df_columns)\n",
    "\n",
    "        gscv_dataframe = gscv_dataframe.append(x_gscv_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Estimators</th>\n",
       "      <th>Max_feats</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Binary)</th>\n",
       "      <th>Recall (Binary)</th>\n",
       "      <th>F1 (Binary)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678097</td>\n",
       "      <td>0.669158</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.766840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675886</td>\n",
       "      <td>0.667687</td>\n",
       "      <td>0.896333</td>\n",
       "      <td>0.765297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672906</td>\n",
       "      <td>0.664288</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.764385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670302</td>\n",
       "      <td>0.662156</td>\n",
       "      <td>0.899889</td>\n",
       "      <td>0.762932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.661246</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>0.762048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classifier Estimators Max_feats  Accuracy  Precision (Binary)  \\\n",
       "14  Isolation Forest        150         1  0.678097            0.669158   \n",
       "4   Isolation Forest         50         1  0.675886            0.667687   \n",
       "19  Isolation Forest        200         1  0.672906            0.664288   \n",
       "9   Isolation Forest        100         1  0.670302            0.662156   \n",
       "1   Isolation Forest         50        10  0.668976            0.661246   \n",
       "\n",
       "    Recall (Binary)  F1 (Binary)  \n",
       "14         0.897917     0.766840  \n",
       "4          0.896333     0.765297  \n",
       "19         0.900000     0.764385  \n",
       "9          0.899889     0.762932  \n",
       "1          0.899111     0.762048  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_dataframe.sort_values('F1 (Binary)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the table above, the ideal solution has 150 estimators and a maximum features value of float 1.0, which takes all the features. This has a slightly better F1-Score than the default model of 100 estimators and 1.0 maximum features, having 0.767 as compared to 0.756."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, both the baseline models of One Class SVM and Isolation Forest seemed to offer similar results, with the preference leaning slightly towards Isolation Forest. Through using only the most important features, it seemed that Isolation Forest would outperform One Class SVM, by considering the F-1 score. Hence, I chose to focus on the Isolation Forest model, iterating over it using Grid Search CV to obtain a better model through choice of hyper-parameters. The final model which I found to have the best F1 score was the __Isolation Forest with 150 estimators and 1.0 Max Features__, with an F1 score of 0.763.\n",
    "One limitation to note was the fact that I had experience pre-processing over the entire dataset in the previous report, including the anomalous dataset, which might have skewed the performance of my models to perform better as I had an idea of which features to look out for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
