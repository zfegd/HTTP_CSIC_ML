{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = pd.read_csv(\"normalTrafficTraining_http_requests.csv\")\n",
    "normalTestDataFrame = pd.read_csv(\"normalTrafficTest_http_requests.csv\")\n",
    "anomalousTestDataFrame = pd.read_csv(\"anomalousTrafficTest_http_requests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataFrame = normalTestDataFrame.append(anomalousTestDataFrame, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.drop(columns=\"Unnamed: 0\")\n",
    "testDataFrame = testDataFrame.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Trivial Features' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the indexes of the columns to drop\n",
    "\n",
    "num_columns = len(testDataFrame.columns)\n",
    "cols_to_drop_index = []\n",
    "\n",
    "for i in range(num_columns):\n",
    "    if len(testDataFrame.iloc[:,i].value_counts()) == 1:\n",
    "        cols_to_drop_index = cols_to_drop_index + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the name of the columns to drop\n",
    "\n",
    "df_columns = testDataFrame.columns\n",
    "cols_to_drop_name = []\n",
    "\n",
    "for i in range(len(cols_to_drop_index)):\n",
    "    next_drop = df_columns[cols_to_drop_index[i]]\n",
    "    cols_to_drop_name = cols_to_drop_name + [next_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame.drop(cols_to_drop_name, axis=1, inplace=True)\n",
    "testDataFrame.drop(cols_to_drop_name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ordering columns\n",
    "def re_order_last_col_to_front(df):\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = re_order_last_col_to_front(normalTrainingDataFrame)\n",
    "testDataFrame = re_order_last_col_to_front(testDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Manipulation - Based on experience in the binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.drop(columns=['Host', 'Cookie'])\n",
    "testDataFrame = testDataFrame.drop(columns=['Host', 'Cookie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping \"http://localhost:8080\" from request_addres\n",
    "normalTrainingDataFrame.rename(columns={'Request_Address':'Request_Address_URI'}, inplace=True)\n",
    "testDataFrame.rename(columns={'Request_Address':'Request_Address_URI'}, inplace=True)\n",
    "normalTrainingDataFrame['Request_Address_URI'] = normalTrainingDataFrame['Request_Address_URI'].apply(lambda x: x[21:])\n",
    "testDataFrame['Request_Address_URI'] = testDataFrame['Request_Address_URI'].apply(lambda x: x[21:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Content-Length'] = normalTrainingDataFrame['Content-Length'].replace(np.nan, 0)\n",
    "testDataFrame['Content-Length'] = testDataFrame['Content-Length'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['No_of_slashes'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"/\"), axis=1)\n",
    "normalTrainingDataFrame['No_of_questions'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"?\"), axis=1)\n",
    "normalTrainingDataFrame['No_of_equals'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"=\"), axis=1)\n",
    "\n",
    "testDataFrame['No_of_slashes'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"/\"), axis=1)\n",
    "testDataFrame['No_of_questions'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"?\"), axis=1)\n",
    "testDataFrame['No_of_equals'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"=\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Put_Request'] = normalTrainingDataFrame['Request_Type'] == \"PUT\"\n",
    "testDataFrame['Put_Request'] = testDataFrame['Request_Type'] == \"PUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['No_of_ampersands'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\"&\"), axis=1)\n",
    "normalTrainingDataFrame['No_of_periods'] = normalTrainingDataFrame.apply(lambda row: row.Request_Address_URI.count(\".\"), axis=1)\n",
    "\n",
    "testDataFrame['No_of_ampersands'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\"&\"), axis=1)\n",
    "testDataFrame['No_of_periods'] = testDataFrame.apply(lambda row: row.Request_Address_URI.count(\".\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Length_of_URI'] = normalTrainingDataFrame.apply(lambda row: len(row.Request_Address_URI), axis=1)\n",
    "\n",
    "testDataFrame['Length_of_URI'] = testDataFrame.apply(lambda row: len(row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(uri):\n",
    "    tokens = uri.split(\".\")\n",
    "    if len(tokens)==1:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return tokens[len(tokens)-1]\n",
    "    \n",
    "def get_final_file(uri):\n",
    "    tokens = uri.split(\"/\")\n",
    "    return tokens[len(tokens)-1]\n",
    "\n",
    "# To try and find bad extensions\n",
    "def max_no_of_periods_between_slashes(uri):\n",
    "    num_found = 0\n",
    "    tokens = uri.split(\"/\")\n",
    "    for token in tokens:\n",
    "        num_in_token = token.count(\".\")\n",
    "        if num_in_token > num_found:\n",
    "            num_found = num_in_token\n",
    "    return num_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['URI_ext'] = normalTrainingDataFrame.apply(lambda row: get_ext(row.Request_Address_URI), axis=1)\n",
    "normalTrainingDataFrame['URI_file'] = normalTrainingDataFrame.apply(lambda row: get_final_file(row.Request_Address_URI), axis=1)\n",
    "normalTrainingDataFrame['Max_no_periods_between_slashes'] = normalTrainingDataFrame.apply(lambda row: max_no_of_periods_between_slashes(row.Request_Address_URI), axis=1)\n",
    "normalTrainingDataFrame['URI_ext_end_with_alpha'] = normalTrainingDataFrame.apply(lambda row: row.URI_ext[-1:].isalpha(), axis=1)\n",
    "normalTrainingDataFrame['URI_ext_end_with_numeric'] = normalTrainingDataFrame.apply(lambda row: row.URI_ext[-1:].isdigit(), axis=1)\n",
    "normalTrainingDataFrame['URI_has_CAPS'] = normalTrainingDataFrame.apply(lambda row: any(x.isupper() for x in row.Request_Address_URI), axis=1)\n",
    "\n",
    "testDataFrame['URI_ext'] = testDataFrame.apply(lambda row: get_ext(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['URI_file'] = testDataFrame.apply(lambda row: get_final_file(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['Max_no_periods_between_slashes'] = testDataFrame.apply(lambda row: max_no_of_periods_between_slashes(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['URI_ext_end_with_alpha'] = testDataFrame.apply(lambda row: row.URI_ext[-1:].isalpha(), axis=1)\n",
    "testDataFrame['URI_ext_end_with_numeric'] = testDataFrame.apply(lambda row: row.URI_ext[-1:].isdigit(), axis=1)\n",
    "testDataFrame['URI_has_CAPS'] = testDataFrame.apply(lambda row: any(x.isupper() for x in row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['URI_ext_shortened'] = normalTrainingDataFrame.apply(lambda row: row.URI_ext[:3], axis=1)\n",
    "\n",
    "testDataFrame['URI_ext_shortened'] = testDataFrame.apply(lambda row: row.URI_ext[:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Referenced from https://stackoverflow.com/questions/1547899/which-characters-make-a-url-invalid \n",
    "URI_CHARS_LIST = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~:/?#[]@!$&'()*+,;=\"\n",
    "\n",
    "def shannon_entropy(data, iterator):\n",
    "    \"\"\"\n",
    "    Borrowed from http://blog.dkbza.org/2007/05/scanning-data-for-entropy-anomalies.html\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return 0\n",
    "    entropy = 0\n",
    "    for x in iterator:\n",
    "        p_x = float(data.count(x))/len(data)\n",
    "        if p_x > 0:\n",
    "            entropy += - p_x*math.log(p_x, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Entropy'] = normalTrainingDataFrame.apply(lambda row: shannon_entropy(row.Request_Address_URI, URI_CHARS_LIST), axis=1)\n",
    "\n",
    "testDataFrame['Entropy'] = testDataFrame.apply(lambda row: shannon_entropy(row.Request_Address_URI, URI_CHARS_LIST), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame['Length_of_URI_File'] = normalTrainingDataFrame.apply(lambda row: len(row.URI_file), axis=1)\n",
    "\n",
    "testDataFrame['Length_of_URI_File'] = testDataFrame.apply(lambda row: len(row.URI_file), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Attacks Detection\n",
    "\n",
    "# To detect JSESSION_ID in URL Rewrite, none of rows contain \"jsessionid=\"\n",
    "normalTrainingDataFrame['Has_set-cookie'] = normalTrainingDataFrame.apply(lambda row: \"Set-cookie\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "testDataFrame['Has_set-cookie'] = testDataFrame.apply(lambda row: \"Set-cookie\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "# Identify accesses to backup files\n",
    "normalTrainingDataFrame['Access_backup'] = normalTrainingDataFrame.apply(lambda row: (row.URI_ext).lower() == \"bak\", axis=1)\n",
    "\n",
    "testDataFrame['Access_backup'] = testDataFrame.apply(lambda row: (row.URI_ext).lower() == \"bak\", axis=1)\n",
    "\n",
    "# Identify accesses to config files\n",
    "normalTrainingDataFrame['Access_config'] = normalTrainingDataFrame.apply(lambda row: (row.URI_ext).lower() == \"cnf\", axis=1)\n",
    "\n",
    "testDataFrame['Access_config'] = testDataFrame.apply(lambda row: (row.URI_ext).lower() == \"cnf\", axis=1)\n",
    "\n",
    "# Identify accesses to default index.html file\n",
    "normalTrainingDataFrame['Access_index_html'] = normalTrainingDataFrame.apply(lambda row: \"index.html\" in row.Request_Address_URI, axis=1)\n",
    "\n",
    "testDataFrame['Access_index_html'] = testDataFrame.apply(lambda row: \"index.html\" in row.Request_Address_URI, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Attacks Detection\n",
    "\n",
    "# Identify possible SQL Commands\n",
    "def spot_sql(uri):\n",
    "    return (\"SELECT\" in uri or \"FROM\" in uri or \"UNION\" in uri or \"OR\" in uri or \"--\" in uri or \"/**/\" in uri or \"INSERT\" in uri or \"UPDATE\" in uri or \"DELETE\" in uri or \"CREATE\" in uri or \"ALTER\" in uri or \"DROP\" in uri)\n",
    "\n",
    "normalTrainingDataFrame['Possible_SQL_Injection'] = normalTrainingDataFrame.apply(lambda row: spot_sql(row.Request_Address_URI), axis=1)\n",
    "testDataFrame['Possible_SQL_Injection'] = testDataFrame.apply(lambda row: spot_sql(row.Request_Address_URI), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross site scripting\n",
    "normalTrainingDataFrame['Contains_script_word'] = normalTrainingDataFrame.apply(lambda row: \"script\" in row.Request_Address_URI.lower(), axis=1)\n",
    "normalTrainingDataFrame['Contains_script_word'] = normalTrainingDataFrame.apply(lambda row: \"script\" in row.Request_Address_URI.lower(), axis=1)\n",
    "\n",
    "testDataFrame['Contains_another_http'] = testDataFrame.apply(lambda row: \"http\" in row.Request_Address_URI.lower(), axis=1)\n",
    "testDataFrame['Contains_another_http'] = testDataFrame.apply(lambda row: \"http\" in row.Request_Address_URI.lower(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidying up of Table - Enumeration and Dropping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.drop(columns=['URI_ext', 'URI_file', 'URI_ext_shortened', 'Request_Address_URI', 'Request_Type'])\n",
    "testDataFrame = testDataFrame.drop(columns=['URI_ext', 'URI_file', 'URI_ext_shortened', 'Request_Address_URI', 'Request_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalTrainingDataFrame = normalTrainingDataFrame.replace([True, False], [1, 0])\n",
    "normalTrainingDataFrame = normalTrainingDataFrame.replace(['No', 'Yes'], [-1,1])\n",
    "\n",
    "testDataFrame = testDataFrame.replace([True, False], [1, 0])\n",
    "testDataFrame = testDataFrame.replace(['No', 'Yes'], [-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalTrainingDataFrame.drop(columns='Normal_Access')\n",
    "y_train = normalTrainingDataFrame['Normal_Access']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testDataFrame.loc[testDataFrame['Normal_Access']==1].drop(columns='Normal_Access')\n",
    "y_test = testDataFrame.loc[testDataFrame['Normal_Access']==1]['Normal_Access']\n",
    "\n",
    "X_outliers = testDataFrame.loc[testDataFrame['Normal_Access']==-1].drop(columns='Normal_Access')\n",
    "y_outliers = testDataFrame.loc[testDataFrame['Normal_Access']==-1]['Normal_Access']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.05, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One class svm\n",
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.OneClassSVM(nu=0.05)\n",
    "svm_clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = svm_clf.predict(X_train)\n",
    "y_pred_test = svm_clf.predict(X_test)\n",
    "y_pred_outliers = svm_clf.predict(X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "result_df_columns = ['Dataset', 'Accuracy', 'Precision (Micro)', 'Precision (Weighted)', 'Recall (Micro)', 'Recall (Weighted)', 'F-1 (Micro)', 'F1 (Weighted)']\n",
    "results_svm_dataframe = pd.DataFrame(columns=result_df_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "\n",
    "x_train_acc = accuracy_score(y_train, y_pred_train)\n",
    "x_train_prec_mic = precision_score(y_train, y_pred_train, average='micro')\n",
    "x_train_prec_mac = precision_score(y_train, y_pred_train, average='weighted')\n",
    "x_train_rec_mic = recall_score(y_train, y_pred_train, average='micro')\n",
    "x_train_rec_mac = recall_score(y_train, y_pred_train, average='weighted')\n",
    "x_train_f1_mic = f1_score(y_train, y_pred_train, average='micro')\n",
    "x_train_f1_mac = f1_score(y_train, y_pred_train, average='weighted')\n",
    "\n",
    "x_train_res = [\"Train\", x_train_acc, x_train_prec_mic, x_train_prec_mac, x_train_rec_mic, x_train_rec_mac, x_train_f1_mic, x_train_f1_mac]\n",
    "x_train_df = pd.DataFrame([x_train_res], columns=result_df_columns)\n",
    "\n",
    "results_svm_dataframe = results_svm_dataframe.append(x_train_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test\n",
    "\n",
    "x_test_acc = accuracy_score(y_test, y_pred_test)\n",
    "x_test_prec_mic = precision_score(y_test, y_pred_test, average='micro')\n",
    "x_test_prec_mac = precision_score(y_test, y_pred_test, average='weighted')\n",
    "x_test_rec_mic = recall_score(y_test, y_pred_test, average='micro')\n",
    "x_test_rec_mac = recall_score(y_test, y_pred_test, average='weighted')\n",
    "x_test_f1_mic = f1_score(y_test, y_pred_test, average='micro')\n",
    "x_test_f1_mac = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "x_test_res = [\"Test\", x_test_acc, x_test_prec_mic, x_test_prec_mac, x_test_rec_mic, x_test_rec_mac, x_test_f1_mic, x_test_f1_mac]\n",
    "x_test_df = pd.DataFrame([x_test_res], columns=result_df_columns)\n",
    "\n",
    "results_svm_dataframe = results_svm_dataframe.append(x_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_outliers\n",
    "x_outliers_acc = accuracy_score(y_outliers, y_pred_outliers)\n",
    "x_outliers_prec_mic = precision_score(y_outliers, y_pred_outliers, average='micro')\n",
    "x_outliers_prec_mac = precision_score(y_outliers, y_pred_outliers, average='weighted')\n",
    "x_outliers_rec_mic = recall_score(y_outliers, y_pred_outliers, average='micro')\n",
    "x_outliers_rec_mac = recall_score(y_outliers, y_pred_outliers, average='weighted')\n",
    "x_outliers_f1_mic = f1_score(y_outliers, y_pred_outliers, average='micro')\n",
    "x_outliers_f1_mac = f1_score(y_outliers, y_pred_outliers, average='weighted')\n",
    "\n",
    "x_outliers_res = [\"Outliers\", x_outliers_acc, x_outliers_prec_mic, x_outliers_prec_mac, x_outliers_rec_mic, x_outliers_rec_mac, x_outliers_f1_mic, x_outliers_f1_mac]\n",
    "x_outliers_df = pd.DataFrame([x_outliers_res], columns=result_df_columns)\n",
    "\n",
    "results_svm_dataframe = results_svm_dataframe.append(x_outliers_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Micro)</th>\n",
       "      <th>Precision (Weighted)</th>\n",
       "      <th>Recall (Micro)</th>\n",
       "      <th>Recall (Weighted)</th>\n",
       "      <th>F-1 (Micro)</th>\n",
       "      <th>F1 (Weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.713083</td>\n",
       "      <td>0.713083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713083</td>\n",
       "      <td>0.713083</td>\n",
       "      <td>0.713083</td>\n",
       "      <td>0.832514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.712361</td>\n",
       "      <td>0.712361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712361</td>\n",
       "      <td>0.712361</td>\n",
       "      <td>0.712361</td>\n",
       "      <td>0.832022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outliers</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>0.816572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Accuracy  Precision (Micro)  Precision (Weighted)  \\\n",
       "0     Train  0.713083           0.713083                   1.0   \n",
       "1      Test  0.712361           0.712361                   1.0   \n",
       "2  Outliers  0.690006           0.690006                   1.0   \n",
       "\n",
       "   Recall (Micro)  Recall (Weighted)  F-1 (Micro)  F1 (Weighted)  \n",
       "0        0.713083           0.713083     0.713083       0.832514  \n",
       "1        0.712361           0.712361     0.712361       0.832022  \n",
       "2        0.690006           0.690006     0.690006       0.816572  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svm_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced Features\n",
    "# Curse of dimensionality crucial in outlier detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
